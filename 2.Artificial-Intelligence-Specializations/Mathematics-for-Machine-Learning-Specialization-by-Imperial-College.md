<img align="right" width="100" height="100" src="https://github.com/cs-MohamedAyman/Coursera-Specializations/blob/master/organizations-logos/imperial%20college%20london.jpg">

# [Mathematics for Machine Learning Specialization](https://www.coursera.org/specializations/mathematics-machine-learning) `60H`

## WHAT YOU WILL LEARN
- Implement mathematical concepts using real-world data
- Derive PCA from a projection perspective
- Understand how orthogonal projections work
- Master PCA

## SKILLS YOU WILL GAIN
`eigenvalues and eigenvectors` `principal component analysis (pca)` `multivariable calculus` `linear algebra` `basis (linear algebra)` `transformation matrix` `linear regression` `vector calculus` `gradient descent` `dimensionality reduction` `python programming`

## About this Specialization
- For a lot of higher level courses in Machine Learning and Data Science, you find you need to freshen up on the basics in mathematics - stuff you may have studied before in school or university, but which was taught in another context, or not very intuitively, such that you struggle to relate it to how it’s used in Computer Science. This specialization aims to bridge that gap, getting you up to speed in the underlying mathematics, building an intuitive understanding, and relating it to Machine Learning and Data Science.

- In the first course on Linear Algebra we look at what linear algebra is and how it relates to data. Then we look through what vectors and matrices are and how to work with them.

- The second course, Multivariate Calculus, builds on this to look at how to optimize fitting functions to get good fits to data. It starts from introductory calculus and then uses the matrices and vectors from the first course to look at data fitting.

- The third course, Dimensionality Reduction with Principal Component Analysis, uses the mathematics from the first two courses to compress high-dimensional data. This course is of intermediate difficulty and will require Python and numpy knowledge.

- At the end of this specialization you will have gained the prerequisite mathematical knowledge to continue your journey and take more advanced courses in machine learning.

## Applied Learning Project
Through the assignments of this specialisation you will use the skills you have learned to produce mini-projects with Python on interactive notebooks, an easy to learn tool which will help you apply the knowledge to real world problems. For example, using linear algebra in order to calculate the page rank of a small simulated internet, applying multivariate calculus in order to train your own neural network, performing a non-linear least squares regression to fit a model to a data set, and using principal component analysis to determine the features of the MNIST digits data set.

<details>
	<summary>Specialization Details</summary>

- In the first course on Linear Algebra we look at what linear algebra is and how it relates to vectors and matrices. Then we look through what vectors and matrices are and how to work with them, including the knotty problem of eigenvalues and eigenvectors, and how to use these to solve problems. Finally we look at how to use these to do fun things with datasets - like how to rotate images of faces and how to extract eigenvectors to look at how the Pagerank algorithm works.

- Since we're aiming at data-driven applications, we'll be implementing some of these ideas in code, not just on pencil and paper. Towards the end of the course, you'll write code blocks and encounter Jupyter notebooks in Python, but don't worry, these will be quite short, focussed on the concepts, and will guide you through if you’ve not coded before. At the end of this course you will have an intuitive understanding of vectors and matrices that will help you bridge the gap into linear algebra problems, and how to apply these concepts to machine learning.

- The second course offers a brief introduction to the multivariate calculus required to build many common machine learning techniques. We start at the very beginning with a refresher on the “rise over run” formulation of a slope, before converting this to the formal definition of the gradient of a function. We then start to build up a set of tools for making calculus easier and faster. Next, we learn how to calculate vectors that point up hill on multidimensional surfaces and even put this into action using an interactive game. We take a look at how we can use calculus to build approximations to functions, as well as helping us to quantify how accurate we should expect those approximations to be. We also spend some time talking about where calculus comes up in the training of neural networks, before finally showing you how it is applied in linear regression models. This course is intended to offer an intuitive understanding of calculus, as well as the language necessary to look concepts up yourselves when you get stuck. Hopefully, without going into too much detail, you’ll still come away with the confidence to dive into some more focused machine learning courses in future.

- This intermediate-level course introduces the mathematical foundations to derive Principal Component Analysis (PCA), a fundamental dimensionality reduction technique. We'll cover some basic statistics of data sets, such as mean values and variances, we'll compute distances and angles between vectors using inner products and derive orthogonal projections of data onto lower-dimensional subspaces. Using all these tools, we'll then derive PCA as a method that minimizes the average squared reconstruction error between data points and their reconstruction.

- At the end of this course, you'll be familiar with important mathematical concepts and you can implement PCA all by yourself. If you’re struggling, you'll find a set of jupyter notebooks that will allow you to explore properties of the techniques and walk you through what you need to do to get on track. If you are already an expert, this course may refresh some of your knowledge. The lectures, examples and exercises require: 
  1. Some ability of abstract thinking 
  2. Good background in linear algebra (e.g., matrix and vector algebra, linear independence, basis) 
  3. Basic background in multivariate calculus (e.g., partial derivatives, basic optimization) 
  4. Basic knowledge in python programming and numpy Disclaimer
- This course is substantially more abstract and requires more programming than the other two courses of the specialization. However, this type of abstract thinking, algebraic manipulation and programming is necessary if you want to understand and develop machine learning algorithms.

</details>

## There are 3 Courses in this Specialization

## Course 1: [Mathematics for Machine Learning: Linear Algebra](https://www.coursera.org/learn/linear-algebra-machine-learning) `20H`

### Week 1: Introduction to Linear Algebra and to Mathematics for Machine Learning
- Welcome to this course
  - Video: Introduction: Solving data science challenges with mathematics
  - Reading: About Imperial College & the team
  - Reading: How to be successful in this course
  - Reading: Grading policy
  - Reading: Additional readings & helpful references
  - Discussion Prompt: Nice to meet you!
  - Complete our short pre-course survey
- The relationship between machine learning, linear algebra, and vectors and matrices
  - Video: Motivations for linear algebra
  - Video: Getting a handle on vectors
  - Practice Quiz: Exploring parameter space
  - Practice Quiz: Solving some simultaneous equations
- Vectors
  - Video: Operations with vectors
  - Practice Quiz: Doing some vector operations
- Summary
  - Video: Summary

### Week 2: Vectors are objects that move around space
- Introduction
  - Video: Introduction to module 2 - Vectors
- Finding the size of a vector, its angle, and projection
  - Video: Modulus & inner product
  - Video: Cosine & dot product
  - Video: Projection
  - Practice Quiz: Dot product of vectors
- Changing the reference frame
  - Video: Changing basis
  - Practice Quiz: Changing basis
  - Video: Basis, vector space, and linear independence
  - Video: Applications of changing basis
  - Practice Quiz: Linear dependency of a set of vectors
- Doing some real-world vectors examples
  - Quiz: Vector operations assessment
  - Video: Summary

### Week 3: Matrices in Linear Algebra: Objects that operate on Vectors
- Introduction to matrices
  - Video: Matrices, vectors, and solving simultaneous equation problems
- Matrices in linear algebra: operating on vectors
  - Video: How matrices transform space
  - Video: Types of matrix transformation
  - Video: Composition or combination of matrix transformations
  - Practice Quiz: Using matrices to make transformations
- Matrix Inverses
  - Video: Solving the apples and bananas problem: Gaussian elimination
  - Video: Going from Gaussian elimination to finding the inverse matrix
  - Practice Quiz: Solving linear equations using the inverse matrix
- Special matrices and Coding up some matrix operations
  - Video: Determinants and inverses
  - Lab: Identifying special matrices
  - Video: Summary
  - Programming Assignment: Identifying special matrices

### Week 4: Matrices make linear mappings
- Matrices as objects that map one vector onto another; all the types of matrices
  - Video: Introduction: Einstein summation convention and the symmetry of the dot product
  - Practice Quiz: Non-square matrix multiplication
  - Practice Quiz: Example: Using non-square matrices to do a projection
- Matrices transform into the new basis vector set
  - Video: Matrices changing basis
  - Video: Doing a transformation in a changed basis
- Making Multiple Mappings, deciding if these are reversible
  - Video: Orthogonal matrices
- Recognising mapping matrices and applying these to data
  - Video: The Gram–Schmidt process
  - Lab: Gram-Schmidt process
  - Video: Example: Reflecting in a plane
  - Lab: Reflecting Bear
  - Programming Assignment: Gram-Schmidt Process
  - Programming Assignment: Reflecting Bear

### Week 5: Eigenvalues and Eigenvectors: Application to Data Problems
- What are eigen-things?
  - Video: Welcome to module 5
  - Video: What are eigenvalues and eigenvectors?
  - Practice Quiz: Selecting eigenvectors by inspection
- Getting into the detail of eigenproblems
  - Video: Special eigen-cases
  - Video: Calculating eigenvectors
  - Practice Quiz: Characteristic polynomials, eigenvalues and eigenvectors
- When changing to the eigenbasis is really useful
  - Video: Changing to the eigenbasis
  - Video: Eigenbasis example
  - Practice Quiz: Diagonalisation and applications
  - Visualising Matrices and Eigen
- Making the PageRank algorithm
  - Video: Introduction to PageRank
  - Lab: PageRank
  - Programming Assignment: Page Rank
- Eigenvalues and Eigenvectors: Assessment
  - Quiz: Eigenvalues and eigenvectors
  - Video: Summary
  - Video: Wrap up of this linear algebra course
  - Reading: Did you like the course? Let us know!
  - Post-Course Survey

## Course 2: [Mathematics for Machine Learning: Multivariate Calculus](https://www.coursera.org/learn/multivariate-calculus-machine-learning) `20H`

### Week 1: What is calculus?
- Welcome to this course
  - Video: Welcome to Multivariate Calculus
  - Reading: About Imperial College & the team
  - Reading: How to be successful in this course
  - Reading: Grading Policy
  - Reading: Additional Readings & Helpful References
  - Discussion Prompt: Nice to meet you!
  - Pre-course Survey
- Back to basics: functions
  - Video: Welcome to Module 1!
  - Video: Functions
  - Practice Quiz: Matching functions visually
- Gradients and derivatives
  - Video: Rise Over Run
  - Practice Quiz: Matching the graph of a function to the graph of its derivative
  - Video: Definition of a derivative
  - Video: Differentiation examples & special cases
  - Practice Quiz: Let's differentiate some functions
- Time saving rules
  - Video: Product rule
  - Practice Quiz: Practicing the product rule
  - Video: Chain rule
  - Video: Taming a beast
  - Practice Quiz: Practicing the chain rule
- Assessment
  - Quiz: Unleashing the toolbox
  - Video: See you next module!

### Week 2: Multivariate calculus
- Moving to multivariate
  - Video: Welcome to Module 2!
  - Video: Variables, constants & context
  - Video: Differentiate with respect to anything
  - Practice Quiz: Practicing partial differentiation
- Jacobians - vectors of derivatives
  - Video: The Jacobian
  - Practice Quiz: Calculating the Jacobian
  - Video: Jacobian applied
  - Practice Quiz: Bigger Jacobians!
- The sandpit game
  - Video: The Sandpit
  - Lab: The Sandpit
  - Lab: The Sandpit - Part 2
  - Video: The Hessian
  - Practice Quiz: Calculating Hessians
  - Video: Reality is hard
  - Quiz: Assessment: Jacobians and Hessians
  - Video: See you next module!

### Week 3: Multivariate chain rule and its applications
- Chain rule intro.
  - Video: Welcome to Module 3!
  - Video: Multivariate chain rule
  - Video: More multivariate chain rule
  - Practice Quiz: Multivariate chain rule exercise
- Neural Networks
  - Video: Simple neural networks
  - Practice Quiz: Simple Artificial Neural Networks
  - Video: More simple neural networks
  - Practice Quiz: Training Neural Networks
  - Lab: Backpropagation
  - Programming Assignment: Backpropagation
  - Discussion Prompt: I love backpropagation
  - Video: See you next module!

### Week 4: Taylor series and linearisation
- Taylor series for approximations
  - Video: Welcome to Module 4!
  - Video: Building approximate functions
  - Video: Power series
  - Practice Quiz: Matching functions and approximations
  - Visualising Taylor Series
  - Video: Power series derivation
  - Video: Power series details
  - Practice Quiz: Applying the Taylor series
  - Video: Examples
- Multivariable Taylor Series
  - Video: Linearisation
  - Practice Quiz: Taylor series - Special cases
  - Video: Multivariate Taylor
  - Practice Quiz: 2D Taylor series
  - Quiz: Taylor Series Assessment
  - Video: See you next module!

### Week 5: Intro to optimisation
- Fitting as minimisation problem
  - Video: Welcome to Module 5!
  - Practice Quiz: Newton-Raphson in one dimension
  - Video: Gradient Descent
  - Lab: Gradient descent in a sandpit
  - Discussion Prompt: Steepest strategies
  - Quiz: Checking Newton-Raphson
- Lagrange multipliers
  - Video: Constrained optimisation
  - Practice Quiz: Lagrange multipliers
- Assessment
  - Quiz: Optimisation scenarios
  - Video: See you next module!

### Week 6: Regression
- Into to linear regression
  - Video: Simple linear regression
  - Practice Quiz: Linear regression
- Non-linear regression
  - Video: General non linear least squares
  - Practice Quiz: Fitting a non-linear function
  - Video: Doing least squares regression analysis in practice
  - Lab: Fitting the distribution of heights data
  - Programming Assignment: Fitting the distribution of height data
  - Video: Wrap up of this course
  - Reading: Did you like the course? Let us know!
  - Post-course Survey

## Course 3: [Mathematics for Machine Learning: PCA](https://www.coursera.org/learn/pca-machine-learning) `20H`

### Week 1: Statistics of Datasets
- Welcome to this course
  - Video: Introduction to the course
  - Reading: About Imperial College & the team
  - Reading: How to be successful in this course
  - Reading: Grading policy
  - Reading: Additional readings & helpful references
  - Discussion Prompt: Nice to meet you!
  - Survey
  - Reading: Mini numpy tutorial
  - Reading: Set up Jupyter notebook environment offline
- Mean values
  - Video: Welcome to module 1
  - Video: Mean of a dataset
  - Practice Quiz: Mean of datasets
- Variances and covariances
  - Video: Variance of one-dimensional datasets
  - Quiz: Variance of 1D datasets
  - Reading: Symmetric, positive definite matrices
  - Video: Variance of higher-dimensional datasets
  - Practice Quiz: Covariance matrix of a two-dimensional dataset
- Linear transformation of datasets
  - Video: Effect on the mean
  - Video: Effect on the (co)variance
  - Lab: Numpy Tutorial
  - Lab: Mean/covariance of a dataset + effect of a linear transformation
  - Programming Assignment: Mean/covariance of a dataset + effect of a linear transformation
  - Video: See you next module!

### Week 2: Inner Products
- Dot product
  - Video: Welcome to module 2
  - Video: Dot product
  - Practice Quiz: Dot product
- Inner products
  - Video: Inner product: definition
  - Quiz: Properties of inner products
  - Video: Inner product: length of vectors
  - Video: Inner product: distances between vectors
  - Practice Quiz: General inner products: lengths and distances
  - Reading: Basis vectors
  - Video: Inner product: angles and orthogonality
  - Quiz: Angles between vectors using a non-standard inner product
  - Lab: Inner products and angles
  - Programming Assignment: Inner products and angles
  - Video: Inner products of functions and random variables (optional)
  - Video: Heading for the next module!

### Week 3: Orthogonal Projections
- Projections
  - Video: Welcome to module 3
  - Video: Projection onto 1D subspaces
  - Video: Example: projection onto 1D subspaces
  - Quiz: Projection onto a 1-dimensional subspace
  - Video: Projections onto higher-dimensional subspaces
  - Reading: Full derivation of the projection
  - Video: Example: projection onto a 2D subspace
  - Practice Quiz: Project 3D data onto a 2D subspace
  - Lab: Orthogonal projections
  - Programming Assignment: Orthogonal projections
  - Video: This was module 3!

### Week 4: Principal Component Analysis
- PCA derivation
  - Video: Welcome to module 4
  - Reading: Vector spaces
  - Reading: Orthogonal complements
  - Video: Problem setting and PCA objective
  - Reading: Multivariate chain rule
  - Practice Quiz: Chain rule practice
  - Video: Finding the coordinates of the projected data
  - Video: Reformulation of the objective
  - Reading: Lagrange multipliers
  - Video: Finding the basis vectors that span the principal subspace
- PCA algorithm
  - Video: Steps of PCA
  - Video: PCA in high dimensions
  - Lab: Principal Components Analysis (PCA)
  - Programming Assignment: PCA
  - Video: Other interpretations of PCA (optional)
  - Video: Summary of this module
  - Video: This was the course on PCA
  - Reading: Did you like the course? Let us know!
  - Post-Course Survey
